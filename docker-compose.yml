version: '3.9'

services:
  config:
    image: ghcr.io/buildingsoftwareblocks/exchange-config
    ports:
      - "8888:8888"
    volumes:
      - ./configuration:/configuration

  exchange_zk:
    image: zookeeper
    ports:
      - "2182:2181"

  kafka_zk:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"

  kafka:
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: ${DOCKER_GATEWAY_HOST:-host.docker.internal}
      KAFKA_ZOOKEEPER_CONNECT: kafka_zk:2181
      KAFKA_MESSAGE_MAX_BYTES: 3000000
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_LOG_RETENTION_BYTES: 53687091200
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_LOG_SEGMENT_DELETE_DELAY_MS: 60000
    depends_on:
      - kafka_zk

  mongo:
    image: mongo:4.4
    ports:
      - "27017-27019:27017-27019"
    restart: always
    volumes:
      - ./data/mongo:/data/db

  nginx:
    image: nginx:stable
    profiles: [ "full" ]
    restart: always
    volumes:
      - ./configuration/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - frontend
    ports:
      - "8081:4000"

  frontend:
    image: ghcr.io/buildingsoftwareblocks/exchange-frontend
    profiles: [ "full" ]
    ports:
      - "8081"
    environment:
      - CONFIG_HOST=config
      - KAFKA_SERVER=kafka
      - ADMIN_SERVER=admin
      - LOGSTASH_SERVER=logstash
      - JAVA_OPTS=-XX:MaxDirectMemorySize=128m -Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector
      - APM="http://apm:8080/"
    depends_on:
      - config
      - kafka
      - logstash

  backend:
    image: ghcr.io/buildingsoftwareblocks/exchange-backend
    profiles: [ "full" ]
    restart: unless-stopped
    ports:
      - "8082"
    environment:
      - CONFIG_HOST=config
      - KAFKA_SERVER=kafka
      - BACKEND_ZOOKEEPER_HOST=exchange_zk:2181
      - MONGO_DB_SERVER=mongo
      - ES_SERVER=elasticsearch
      - LOGSTASH_SERVER=logstash
      - APM="http://apm:8080/"
      - JAVA_OPTS=-XX:MaxDirectMemorySize=128m -Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector
      - ADMIN_SERVER=admin
      - BACKEND_RECORDING=false
      - BACKEND_REPLAY=false
    depends_on:
      config:
        condition: service_started
      mongo:
        condition: service_started
      kafka:
        condition: service_started
      exchange_zk:
        condition: service_started
      logstash:
        condition: service_started
      elasticsearch:
        condition: service_healthy

  analysis:
    image: ghcr.io/buildingsoftwareblocks/exchange-analysis
    profiles: [ "full" ]
    ports:
      - "8083"
    environment:
      - CONFIG_HOST=config
      - KAFKA_SERVER=kafka
      - LOGSTASH_SERVER=logstash
      - ADMIN_SERVER=admin
      - JAVA_OPTS=-XX:MaxDirectMemorySize=128m -Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector
      - APM="http://apm:8080/"
      - ANALYSIS_BUYFEES=0
      - ANALYSIS_SELLFEES=0
      - ANALYSIS_TRANSPORTFEES=0.1
    depends_on:
      - config
      - kafka
      - logstash

  admin:
    image: ghcr.io/buildingsoftwareblocks/exchange-admin
    depends_on:
      - config
    ports:
      - "8080:8080"

  #
  # https://github.com/deviantony/docker-elk
  #
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.8
    volumes:
      - ./configuration/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
      - ./data/elasticsearch:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: "-Xmx4g -Xms4g"
      ELASTIC_PASSWORD: changeme
      # Use single node discovery in order to disable production mode and avoid bootstrap checks.
      # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node
    healthcheck:
      test: curl -s http://elasticsearch:9200 >/dev/null || exit 1
      interval: 30s
      timeout: 10s
      retries: 50

  logstash:
    image: docker.elastic.co/logstash/logstash:7.17.8
    volumes:
      - ./configuration/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./configuration/pipeline:/usr/share/logstash/pipeline
    ports:
      - "5044:5044"
      - "5000:5000/tcp"
      - "5000:5000/udp"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: "-Xmx512m -Xms512m"

  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.8
    volumes:
      - ./configuration/kibana.yml:/usr/share/kibana/config/kibana.yml
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

  apm:
    image: ghcr.io/buildingsoftwareblocks/apm
    ports:
      - "7777:8080"
    environment:
      APM_RESOLUTION: 30
