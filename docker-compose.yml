version: '3'

services:
  exchange_zk:
    image: zookeeper
    ports:
      - "2181"

  kafka_zk:
    image: wurstmeister/zookeeper
    ports:
      - "2181"

  kafka:
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: ${DOCKER_GATEWAY_HOST:-host.docker.internal}
      KAFKA_ZOOKEEPER_CONNECT: kafka_zk:2181
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_LOG_RETENTION_BYTES: 53687091200
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_LOG_SEGMENT_DELETE_DELAY_MS: 60000
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./data/kafka:/kafka
    depends_on:
      - kafka_zk

  mongo:
    image: mongo
    ports:
      - 27017-27019:27017-27019
    volumes:
      - ./data/mongo:/data/db

  nginx:
    image: nginx:latest
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - frontend
    ports:
      - "8081:4000"

  frontend:
    image: ${REPO}/exchange-frontend
    ports:
      - "8081"
    environment:
      - KAFKA_SERVER=kafka
      - ADMIN_SERVER=admin
      - LOGSTASH_SERVER=logstash
      - JAVA_OPTS=-XX:MaxDirectMemorySize=128m
    depends_on:
      - kafka

  backend:
    image: ${REPO}/exchange-backend
    ports:
      - "8082"
    environment:
      - KAFKA_SERVER=kafka
      - BACKEND_ZOOKEEPER=exchange_zk:2181
      - MONGO_DB_SERVER=mongo
      - LOGSTASH_SERVER=logstash
      - ADMIN_SERVER=admin
      - BACKEND_RECORDING=false
      - BACKEND_REPLAY=false
      - JAVA_OPTS=-XX:MaxDirectMemorySize=128m
    depends_on:
      - mongo
      - kafka
      - exchange_zk

  analysis:
    image: ${REPO}/exchange-analysis
    ports:
      - "8083"
    environment:
      - KAFKA_SERVER=kafka
      - LOGSTASH_SERVER=logstash
      - ADMIN_SERVER=admin
      - JAVA_OPTS=-XX:MaxDirectMemorySize=128m
      - ANALYSIS_BUYFEES=0
      - ANALYSIS_SELLFEES=0
      - ANALYSIS_TRANSPORTFEES=0.1
    depends_on:
      - kafka

  admin:
    image: ${REPO}/exchange-admin
    ports:
      - "8080:8080"

#
# https://github.com/deviantony/docker-elk
#
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:$ELK_VERSION
    volumes:
      - ./config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
      - ./data/elasticsearch:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: "-Xmx1024m -Xms1024m"
      ELASTIC_PASSWORD: changeme
      # Use single node discovery in order to disable production mode and avoid bootstrap checks.
      # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node

  logstash:
    image: docker.elastic.co/logstash/logstash:${ELK_VERSION}
    volumes:
      - ./config/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./config/pipeline:/usr/share/logstash/pipeline
    ports:
      - "5044:5044"
      - "5000:5000/tcp"
      - "5000:5000/udp"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:${ELK_VERSION}
    volumes:
      - ./config/kibana.yml:/usr/share/kibana/config/kibana.yml
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch